python demo.py --train_iteration=1000 -l=0.001
----------------------------------------------
Warning: transition_bias cannot be correctly estimated from a concatenated sequence; train_sequences will be treated as a single sequence. This can lead to inaccurate estimation of transition_bias. Please, consider estimating transition_bias before concatenating the sequences and passing it as argument.
Iter: 0  	Training Loss: -284.0683    
    Negative Log Likelihood: 6.0584	Sigma2 Prior: -290.1273	Regularization: 0.0006
Iter: 10  	Training Loss: -297.7010    
    Negative Log Likelihood: 5.6607	Sigma2 Prior: -303.3623	Regularization: 0.0006
Iter: 20  	Training Loss: -311.9828    
    Negative Log Likelihood: 6.2843	Sigma2 Prior: -318.2677	Regularization: 0.0006
Iter: 30  	Training Loss: -325.6216    
    Negative Log Likelihood: 7.1480	Sigma2 Prior: -332.7702	Regularization: 0.0006
Iter: 40  	Training Loss: -343.9665    
    Negative Log Likelihood: 8.3391	Sigma2 Prior: -352.3062	Regularization: 0.0006
Iter: 50  	Training Loss: -369.4339    
    Negative Log Likelihood: 10.4304	Sigma2 Prior: -379.8649	Regularization: 0.0007
Iter: 60  	Training Loss: -400.1983    
    Negative Log Likelihood: 14.0643	Sigma2 Prior: -414.2632	Regularization: 0.0007
Iter: 70  	Training Loss: -448.3654    
    Negative Log Likelihood: 22.6297	Sigma2 Prior: -470.9958	Regularization: 0.0007
Iter: 80  	Training Loss: -490.4100    
    Negative Log Likelihood: 58.1928	Sigma2 Prior: -548.6034	Regularization: 0.0007
Iter: 90  	Training Loss: -468.6420    
    Negative Log Likelihood: 40.3007	Sigma2 Prior: -508.9434	Regularization: 0.0007
Iter: 100  	Training Loss: -464.4588    
    Negative Log Likelihood: 38.6238	Sigma2 Prior: -503.0833	Regularization: 0.0007
Iter: 110  	Training Loss: -490.0394    
    Negative Log Likelihood: 52.4841	Sigma2 Prior: -542.5242	Regularization: 0.0007
Iter: 120  	Training Loss: -461.0431    
    Negative Log Likelihood: 49.4676	Sigma2 Prior: -510.5114	Regularization: 0.0007
Iter: 130  	Training Loss: -478.4829    
    Negative Log Likelihood: 45.7020	Sigma2 Prior: -524.1857	Regularization: 0.0008
Iter: 140  	Training Loss: -486.9563    
    Negative Log Likelihood: 47.6244	Sigma2 Prior: -534.5814	Regularization: 0.0008
Iter: 150  	Training Loss: -463.8262    
    Negative Log Likelihood: 42.2884	Sigma2 Prior: -506.1154	Regularization: 0.0008
Iter: 160  	Training Loss: -454.8089    
    Negative Log Likelihood: 48.3903	Sigma2 Prior: -503.2000	Regularization: 0.0008
Iter: 170  	Training Loss: -489.0232    
    Negative Log Likelihood: 43.3898	Sigma2 Prior: -532.4138	Regularization: 0.0008
Iter: 180  	Training Loss: -493.3049    
    Negative Log Likelihood: 39.1315	Sigma2 Prior: -532.4372	Regularization: 0.0008
Iter: 190  	Training Loss: -464.7241    
    Negative Log Likelihood: 45.1158	Sigma2 Prior: -509.8407	Regularization: 0.0009
Iter: 200  	Training Loss: -480.2109    
    Negative Log Likelihood: 38.6267	Sigma2 Prior: -518.8385	Regularization: 0.0009
Iter: 210  	Training Loss: -473.6754    
    Negative Log Likelihood: 38.4289	Sigma2 Prior: -512.1052	Regularization: 0.0009
Iter: 220  	Training Loss: -474.5795    
    Negative Log Likelihood: 42.6973	Sigma2 Prior: -517.2777	Regularization: 0.0009
Iter: 230  	Training Loss: -462.8022    
    Negative Log Likelihood: 41.2392	Sigma2 Prior: -504.0424	Regularization: 0.0009
Iter: 240  	Training Loss: -460.8238    
    Negative Log Likelihood: 41.0149	Sigma2 Prior: -501.8397	Regularization: 0.0009
Iter: 250  	Training Loss: -497.9112    
    Negative Log Likelihood: 46.0860	Sigma2 Prior: -543.9981	Regularization: 0.0010
Iter: 260  	Training Loss: -462.5835    
    Negative Log Likelihood: 40.4661	Sigma2 Prior: -503.0506	Regularization: 0.0010
Iter: 270  	Training Loss: -500.2110    
    Negative Log Likelihood: 35.7056	Sigma2 Prior: -535.9176	Regularization: 0.0010
Iter: 280  	Training Loss: -500.5584    
    Negative Log Likelihood: 45.5855	Sigma2 Prior: -546.1450	Regularization: 0.0010
Iter: 290  	Training Loss: -463.3490    
    Negative Log Likelihood: 36.1925	Sigma2 Prior: -499.5424	Regularization: 0.0010
Iter: 300  	Training Loss: -494.3094    
    Negative Log Likelihood: 46.8865	Sigma2 Prior: -541.1969	Regularization: 0.0010
Iter: 310  	Training Loss: -499.6382    
    Negative Log Likelihood: 42.1572	Sigma2 Prior: -541.7965	Regularization: 0.0010
Iter: 320  	Training Loss: -506.2897    
    Negative Log Likelihood: 43.9054	Sigma2 Prior: -550.1961	Regularization: 0.0011
Iter: 330  	Training Loss: -498.0398    
    Negative Log Likelihood: 37.6732	Sigma2 Prior: -535.7141	Regularization: 0.0011
Iter: 340  	Training Loss: -514.8110    
    Negative Log Likelihood: 43.1272	Sigma2 Prior: -557.9393	Regularization: 0.0011
Iter: 350  	Training Loss: -501.5559    
    Negative Log Likelihood: 31.8641	Sigma2 Prior: -533.4211	Regularization: 0.0011
Iter: 360  	Training Loss: -484.5121    
    Negative Log Likelihood: 35.3397	Sigma2 Prior: -519.8529	Regularization: 0.0011
Iter: 370  	Training Loss: -467.8173    
    Negative Log Likelihood: 47.5453	Sigma2 Prior: -515.3637	Regularization: 0.0011
Iter: 380  	Training Loss: -452.4552    
    Negative Log Likelihood: 40.9772	Sigma2 Prior: -493.4336	Regularization: 0.0011
Iter: 390  	Training Loss: -487.5080    
    Negative Log Likelihood: 36.6616	Sigma2 Prior: -524.1707	Regularization: 0.0011
Iter: 400  	Training Loss: -465.5619    
    Negative Log Likelihood: 38.4146	Sigma2 Prior: -503.9777	Regularization: 0.0011
Iter: 410  	Training Loss: -497.2474    
    Negative Log Likelihood: 30.9535	Sigma2 Prior: -528.2020	Regularization: 0.0011
Iter: 420  	Training Loss: -498.1579    
    Negative Log Likelihood: 43.0121	Sigma2 Prior: -541.1711	Regularization: 0.0012
Iter: 430  	Training Loss: -495.0621    
    Negative Log Likelihood: 35.9665	Sigma2 Prior: -531.0298	Regularization: 0.0012
Iter: 440  	Training Loss: -463.5321    
    Negative Log Likelihood: 39.1597	Sigma2 Prior: -502.6930	Regularization: 0.0012
Iter: 450  	Training Loss: -471.6937    
    Negative Log Likelihood: 43.1244	Sigma2 Prior: -514.8193	Regularization: 0.0012
Iter: 460  	Training Loss: -481.9350    
    Negative Log Likelihood: 36.9677	Sigma2 Prior: -518.9039	Regularization: 0.0012
Iter: 470  	Training Loss: -478.4063    
    Negative Log Likelihood: 44.1152	Sigma2 Prior: -522.5226	Regularization: 0.0012
Iter: 480  	Training Loss: -478.3178    
    Negative Log Likelihood: 37.3863	Sigma2 Prior: -515.7053	Regularization: 0.0012
Iter: 490  	Training Loss: -495.2677    
    Negative Log Likelihood: 34.6089	Sigma2 Prior: -529.8779	Regularization: 0.0012
Iter: 500  	Training Loss: -468.1097    
    Negative Log Likelihood: 39.4279	Sigma2 Prior: -507.5388	Regularization: 0.0012
Iter: 510  	Training Loss: -490.8467    
    Negative Log Likelihood: 38.7392	Sigma2 Prior: -529.5872	Regularization: 0.0012
Iter: 520  	Training Loss: -430.9022    
    Negative Log Likelihood: 39.7234	Sigma2 Prior: -470.6268	Regularization: 0.0012
Iter: 530  	Training Loss: -511.8909    
    Negative Log Likelihood: 35.5908	Sigma2 Prior: -547.4830	Regularization: 0.0012
Iter: 540  	Training Loss: -447.6295    
    Negative Log Likelihood: 44.4914	Sigma2 Prior: -492.1222	Regularization: 0.0012
Iter: 550  	Training Loss: -494.3884    
    Negative Log Likelihood: 42.7291	Sigma2 Prior: -537.1188	Regularization: 0.0012
Iter: 560  	Training Loss: -493.6035    
    Negative Log Likelihood: 36.8751	Sigma2 Prior: -530.4799	Regularization: 0.0013
Iter: 570  	Training Loss: -472.9188    
    Negative Log Likelihood: 36.7021	Sigma2 Prior: -509.6222	Regularization: 0.0013
Iter: 580  	Training Loss: -513.3970    
    Negative Log Likelihood: 35.5637	Sigma2 Prior: -548.9619	Regularization: 0.0013
Iter: 590  	Training Loss: -506.5179    
    Negative Log Likelihood: 42.2112	Sigma2 Prior: -548.7303	Regularization: 0.0013
Iter: 600  	Training Loss: -489.0894    
    Negative Log Likelihood: 34.5576	Sigma2 Prior: -523.6483	Regularization: 0.0013
Iter: 610  	Training Loss: -475.9960    
    Negative Log Likelihood: 38.3117	Sigma2 Prior: -514.3090	Regularization: 0.0013
Iter: 620  	Training Loss: -466.2941    
    Negative Log Likelihood: 36.9264	Sigma2 Prior: -503.2217	Regularization: 0.0013
Iter: 630  	Training Loss: -494.2096    
    Negative Log Likelihood: 38.2317	Sigma2 Prior: -532.4426	Regularization: 0.0013
Iter: 640  	Training Loss: -466.5292    
    Negative Log Likelihood: 41.3780	Sigma2 Prior: -507.9086	Regularization: 0.0013
Iter: 650  	Training Loss: -502.3614    
    Negative Log Likelihood: 35.4669	Sigma2 Prior: -537.8296	Regularization: 0.0013
Iter: 660  	Training Loss: -497.3277    
    Negative Log Likelihood: 33.2167	Sigma2 Prior: -530.5457	Regularization: 0.0013
Iter: 670  	Training Loss: -499.9118    
    Negative Log Likelihood: 38.4551	Sigma2 Prior: -538.3682	Regularization: 0.0013
Iter: 680  	Training Loss: -494.3820    
    Negative Log Likelihood: 39.3854	Sigma2 Prior: -533.7688	Regularization: 0.0013
Iter: 690  	Training Loss: -502.0073    
    Negative Log Likelihood: 35.8461	Sigma2 Prior: -537.8547	Regularization: 0.0013
Iter: 700  	Training Loss: -480.8858    
    Negative Log Likelihood: 36.4607	Sigma2 Prior: -517.3479	Regularization: 0.0013
Iter: 710  	Training Loss: -483.4030    
    Negative Log Likelihood: 36.2874	Sigma2 Prior: -519.6917	Regularization: 0.0013
Iter: 720  	Training Loss: -500.6246    
    Negative Log Likelihood: 35.1528	Sigma2 Prior: -535.7788	Regularization: 0.0013
Iter: 730  	Training Loss: -451.7695    
    Negative Log Likelihood: 41.0625	Sigma2 Prior: -492.8334	Regularization: 0.0013
Iter: 740  	Training Loss: -473.3535    
    Negative Log Likelihood: 36.6081	Sigma2 Prior: -509.9629	Regularization: 0.0014
Iter: 750  	Training Loss: -477.3725    
    Negative Log Likelihood: 33.8116	Sigma2 Prior: -511.1855	Regularization: 0.0014
Iter: 760  	Training Loss: -477.4671    
    Negative Log Likelihood: 37.5779	Sigma2 Prior: -515.0463	Regularization: 0.0014
Iter: 770  	Training Loss: -469.3088    
    Negative Log Likelihood: 41.8721	Sigma2 Prior: -511.1823	Regularization: 0.0014
Iter: 780  	Training Loss: -485.5595    
    Negative Log Likelihood: 37.8505	Sigma2 Prior: -523.4114	Regularization: 0.0014
Iter: 790  	Training Loss: -468.1859    
    Negative Log Likelihood: 38.4603	Sigma2 Prior: -506.6476	Regularization: 0.0014
Iter: 800  	Training Loss: -492.5415    
    Negative Log Likelihood: 35.2791	Sigma2 Prior: -527.8220	Regularization: 0.0014
Iter: 810  	Training Loss: -498.2440    
    Negative Log Likelihood: 36.1687	Sigma2 Prior: -534.4140	Regularization: 0.0014
Iter: 820  	Training Loss: -488.0205    
    Negative Log Likelihood: 34.9399	Sigma2 Prior: -522.9619	Regularization: 0.0014
Iter: 830  	Training Loss: -458.5899    
    Negative Log Likelihood: 42.7226	Sigma2 Prior: -501.3140	Regularization: 0.0014
Iter: 840  	Training Loss: -472.8149    
    Negative Log Likelihood: 37.2683	Sigma2 Prior: -510.0847	Regularization: 0.0014
Iter: 850  	Training Loss: -505.6985    
    Negative Log Likelihood: 32.9117	Sigma2 Prior: -538.6116	Regularization: 0.0014
Iter: 860  	Training Loss: -514.1638    
    Negative Log Likelihood: 41.2610	Sigma2 Prior: -555.4263	Regularization: 0.0014
Iter: 870  	Training Loss: -507.8930    
    Negative Log Likelihood: 33.8785	Sigma2 Prior: -541.7729	Regularization: 0.0014
Iter: 880  	Training Loss: -505.4427    
    Negative Log Likelihood: 37.8381	Sigma2 Prior: -543.2823	Regularization: 0.0014
Iter: 890  	Training Loss: -478.1646    
    Negative Log Likelihood: 34.4769	Sigma2 Prior: -512.6429	Regularization: 0.0014
Iter: 900  	Training Loss: -455.4056    
    Negative Log Likelihood: 42.3209	Sigma2 Prior: -497.7279	Regularization: 0.0014
Iter: 910  	Training Loss: -464.7213    
    Negative Log Likelihood: 34.1027	Sigma2 Prior: -498.8255	Regularization: 0.0014
Iter: 920  	Training Loss: -458.5134    
    Negative Log Likelihood: 40.8954	Sigma2 Prior: -499.4102	Regularization: 0.0014
Iter: 930  	Training Loss: -491.4907    
    Negative Log Likelihood: 30.7630	Sigma2 Prior: -522.2551	Regularization: 0.0014
Iter: 940  	Training Loss: -490.5158    
    Negative Log Likelihood: 35.3407	Sigma2 Prior: -525.8580	Regularization: 0.0014
Iter: 950  	Training Loss: -444.2615    
    Negative Log Likelihood: 35.7575	Sigma2 Prior: -480.0204	Regularization: 0.0014
Iter: 960  	Training Loss: -466.5313    
    Negative Log Likelihood: 41.7077	Sigma2 Prior: -508.2405	Regularization: 0.0015
Iter: 970  	Training Loss: -451.0334    
    Negative Log Likelihood: 32.4654	Sigma2 Prior: -483.5002	Regularization: 0.0015
Iter: 980  	Training Loss: -472.0140    
    Negative Log Likelihood: 35.6507	Sigma2 Prior: -507.6661	Regularization: 0.0015
Iter: 990  	Training Loss: -511.7905    
    Negative Log Likelihood: 42.4627	Sigma2 Prior: -554.2547	Regularization: 0.0015
Iter: 999  	Training Loss: -516.8275    
    Negative Log Likelihood: 36.3660	Sigma2 Prior: -553.1949	Regularization: 0.0015
Done training with 1000 iterations
Ground truth labels:
['15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_0', '15_0', '15_0', '15_0', '15_0', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]
--------------------------------------------------------------------------------
Ground truth labels:
['30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_1']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]
--------------------------------------------------------------------------------
Ground truth labels:
['52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
--------------------------------------------------------------------------------
Ground truth labels:
['71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2]
--------------------------------------------------------------------------------
Ground truth labels:
['75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_2', '75_2', '75_2', '75_2', '75_2', '75_2', '75_2', '75_2', '75_2', '75_2', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_3', '75_3', '75_3', '75_3', '75_3', '75_3', '75_3', '75_3', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_2', '75_2', '75_2', '75_2', '75_2', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_3', '75_3', '75_3', '75_3', '75_3', '75_1', '75_1', '75_1', '75_1', '75_1', '75_1', '75_1', '75_1', '75_2', '75_2', '75_2']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1]
--------------------------------------------------------------------------------
Ground truth labels:
['80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
--------------------------------------------------------------------------------
Ground truth labels:
['140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_2', '140_2', '140_2', '140_2', '140_2', '140_5', '140_5', '140_5', '140_5', '140_5', '140_5', '140_5', '140_5', '140_5', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
--------------------------------------------------------------------------------
Ground truth labels:
['146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
--------------------------------------------------------------------------------
Ground truth labels:
['152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_2', '152_2', '152_2', '152_2']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4]
--------------------------------------------------------------------------------
Ground truth labels:
['175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_1', '175_1', '175_1', '175_1']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3]
--------------------------------------------------------------------------------
Ground truth labels:
['204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_0', '204_0', '204_0', '204_0', '204_0', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
--------------------------------------------------------------------------------
Ground truth labels:
['315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_4', '315_4', '315_4', '315_4', '315_4', '315_4', '315_4', '315_4', '315_4', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_5', '315_5', '315_5', '315_5']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 5, 5, 5]
--------------------------------------------------------------------------------
Ground truth labels:
['333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1']
Predicted labels:
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]
--------------------------------------------------------------------------------
Ground truth labels:
['347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0']
Predicted labels:
[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Finished diarization experiment
Config:
  sigma_alpha: 1.0
  sigma_beta: 1.0
  crp_alpha: 1.0
  learning rate: 0.001
  regularization: 1e-05
  batch size: 10

Performance:
  averaged accuracy: 0.996354
  accuracy numbers for all testing sequences:
    1.000000
    0.988764
    1.000000
    1.000000
    1.000000
    1.000000
    0.989583
    1.000000
    0.990196
    0.989362
    0.989362
    0.989796
    1.000000
    0.989130
    1.000000
    1.000000
    0.990654
    1.000000
    1.000000
    1.000000
    1.000000
    1.000000
    0.992000
    1.000000
    1.000000
================================================================================
